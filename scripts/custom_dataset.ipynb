{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom-dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7IEYPte6jom",
        "colab_type": "text"
      },
      "source": [
        "# Installs and Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8I78pC26m9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependencies:\n",
        "# (use +cu100 because colab is on CUDA 10.0)\n",
        "!pip install -U torch==1.4+cu100 torchvision==0.5+cu100 -f https://download.pytorch.org/whl/torch_stable.html \n",
        "!pip install cython pyyaml==5.1\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "import torch, torchvision\n",
        "torch.__version__\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-oRr5jE6n4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install detectron2:\n",
        "!git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "!pip install -e detectron2_repo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhtGJJHa6rbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbtz7Pbs6u_u",
        "colab_type": "text"
      },
      "source": [
        "# Balloons Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osavDgMx6xBe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "# # This function will return the items in our dataset\n",
        "# def get_balloon_dicts(img_dir):\n",
        "#     # Find the json file in our file structure\n",
        "#     json_file = os.path.join(img_dir, \"via_region_data.json\")\n",
        "#     # Open the file, referring it as f\n",
        "#     with open(json_file) as f:\n",
        "#         # Get the image annotations out using json to read the file containin the JSON object\n",
        "#         imgs_anns = json.load(f)\n",
        "\n",
        "#     # List of dictionaries\n",
        "#     dataset_dicts = []\n",
        "#     # Loop over the image annotation values, using idx as the indexer and v to be the value\n",
        "#     for idx, v in enumerate(imgs_anns.values()):\n",
        "#         # Create a dictionary for the current iteration\n",
        "#         record = {}\n",
        "        \n",
        "#         # Get the filename out of the file - \"filename\" is a key in the json file\n",
        "#         filename = os.path.join(img_dir, v[\"filename\"])\n",
        "#         # Get the height and width out using opencv\n",
        "#         height, width = cv2.imread(filename).shape[:2]\n",
        "        \n",
        "#         # The full path to the image file\n",
        "#         record[\"file_name\"] = filename\n",
        "#         # A unique id that identifies this image\n",
        "#         record[\"image_id\"] = idx\n",
        "#         # Shape of the image\n",
        "#         record[\"height\"] = height\n",
        "#         record[\"width\"] = width\n",
        "      \n",
        "#         # get all annotations, using the regions key - \"regions\" is a key in the json file\n",
        "#         annos = v[\"regions\"]\n",
        "#         # List of objects\n",
        "#         objs = []\n",
        "#         # For each annotation in the list of annotations\n",
        "#         for _, anno in annos.items():\n",
        "#             # assert throws an AssertionError if untrue\n",
        "#             # I think this is just to make sure region attributes is empty\n",
        "#             assert not anno[\"region_attributes\"]\n",
        "            \n",
        "#             # Turn the annotation into the shape attributes object in the file\n",
        "#             anno = anno[\"shape_attributes\"]\n",
        "#             # Get all x and y points\n",
        "#             px = anno[\"all_points_x\"]\n",
        "#             py = anno[\"all_points_y\"]\n",
        "#             # form a list of polygons, some mad functional stuff here\n",
        "#             poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
        "#             poly = [p for x in poly for p in x]\n",
        "\n",
        "#             # Form the object that will form our annotations\n",
        "#             obj = {\n",
        "#                 # list of 4 numbers representing the bounding box\n",
        "#                 \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "#                 # format of the bbox (must be a member of structures.BoxMode)\n",
        "#                 \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "#                 # list of list of floats, where a list of floats is a polygon\n",
        "#                 # so this is a list of polygons for segmentation\n",
        "#                 \"segmentation\": [poly],\n",
        "#                 # the category label, integer from 0 to numCategories - see Categorical Data\n",
        "#                 \"category_id\": 0,\n",
        "#                 # 0 or 1, whether this instance is labeled as COCO's crowd regions - don't include this if you don't know what this means\n",
        "#                 \"iscrowd\": 0\n",
        "#             }\n",
        "#             objs.append(obj)\n",
        "        \n",
        "#         # The per-instance annotation of every instance in this image\n",
        "#         record[\"annotations\"] = objs\n",
        "\n",
        "#         # Append this record\n",
        "#         dataset_dicts.append(record)\n",
        "        \n",
        "#         ### Loop end ###\n",
        "    \n",
        "#     # return the list of dictionaries\n",
        "#     return dataset_dicts\n",
        "\n",
        "# # We tell detectron2 about our newly created function\n",
        "# from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "# for d in [\"train\", \"val\"]:\n",
        "#     # Register this dataset in the catalog of datasets\n",
        "#     DatasetCatalog.register(\"balloon_\" + d, lambda d=d: get_balloon_dicts(\"balloon/\" + d))\n",
        "#     # Get the metadata catalog and add the corresponding metadata\n",
        "#     ## Metadata is a key-value mapping that contains primitive information that helps interpret what's in the dataset (eg names of classes)\n",
        "#     ## Useful for augmentation, evaluation, visualisation, logging, etc.\n",
        "#     MetadataCatalog.get(\"balloon_\" + d).set(thing_classes=[\"balloon\"])\n",
        "# balloon_metadata = MetadataCatalog.get(\"balloon_train\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmLkvwOx6xWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset_dicts = get_balloon_dicts(\"balloon/train\")\n",
        "# for d in random.sample(dataset_dicts, 3):\n",
        "#     img = cv2.imread(d[\"file_name\"])\n",
        "#     visualizer = Visualizer(img[:, :, ::-1], metadata=balloon_metadata, scale=0.5)\n",
        "#     vis = visualizer.draw_dataset_dict(d)\n",
        "#     cv2_imshow(vis.get_image()[:, :, ::-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "up-zwC0g-MIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from detectron2.engine import DefaultTrainer\n",
        "# from detectron2.config import get_cfg\n",
        "\n",
        "# # COCO-Detection/faster_rcnn_R_50_C4_1x.yaml\n",
        "# # COCO-Detection/retinanet_R_50_FPN_1x.yaml\n",
        "\n",
        "# # default configuration\n",
        "# cfg = get_cfg()\n",
        "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "# # get the pretrained retinanet model\n",
        "# # cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/retinanet_R_50_FPN_1x.yaml\"))\n",
        "# # list of the dataset names for training (registered in datasetcatalog (?))\n",
        "# cfg.DATASETS.TRAIN = (\"balloon_train\",)\n",
        "# # list of the dataset names for testing (registered in datasetcatalog (?))\n",
        "# cfg.DATASETS.TEST = ()\n",
        "\n",
        "# # number of data loading threads\n",
        "# cfg.DATALOADER.NUM_WORKERS = 2\n",
        "\n",
        "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "# # locate the pretrained weights\n",
        "# # cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/retinanet_R_50_FPN_1x.yaml\")  # Let training initialize from model zoo\n",
        "\n",
        "# # number of images per batch\n",
        "# cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "# # learning rate\n",
        "# cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "# # max iterations\n",
        "# cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
        "\n",
        "# # Minibatch size PER image - number of regions of interest (ROIs)\n",
        "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # faster, and good enough for this toy dataset (default: 512)\n",
        "# # Number of classes\n",
        "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (ballon)\n",
        "\n",
        "# # directories (?)\n",
        "# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# # Get the default trainer:\n",
        "# ## 1) Create model, optimiser, scheduler, dataloader from the given config\n",
        "# ## 2) Load a checkpoint or cfg.MODEL.WEIGHTS if it exists\n",
        "# ## 3) Register a few common hooks (?)\n",
        "# ## This simplifies the standard model training workflow, so you don't have to write boilerplate code\n",
        "# trainer = DefaultTrainer(cfg)\n",
        "# # If true, and the last checkpoint exists, resume from it\n",
        "# # If false, load a model specified by the config\n",
        "# trainer.resume_or_load(resume=False)\n",
        "# trainer.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMCxnjr-60Xn",
        "colab_type": "text"
      },
      "source": [
        "# Sharks Dataset 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-9iiFbeE-tW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "672aa212-0564-4bbc-9f18-bcbc8aaf866e"
      },
      "source": [
        "# Playing around with the json\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "# from detectron2.structures import BoxMode\n",
        "\n",
        "# This function will return the items in our dataset\n",
        "def get_shark_dicts(img_dir):\n",
        "    # Find the json file in our file structure\n",
        "    json_file = os.path.join(img_dir, \"data.json\")\n",
        "    # Open the file, referring it as f\n",
        "    with open(json_file) as f:\n",
        "        # Get the image annotations out using json to read the file containin the JSON object\n",
        "        imgs_anns = json.load(f)\n",
        "\n",
        "    # List of dictionaries\n",
        "    dataset_dicts = []\n",
        "    # Loop over the image annotation values, using idx as the indexer and v to be the value\n",
        "    for idx, v in enumerate(imgs_anns.values()):\n",
        "        # Create a dictionary for the current iteration\n",
        "        record = {}\n",
        "        \n",
        "        # Get the filename out of the file - \"filename\" is a key in the json file\n",
        "        filename = os.path.join(img_dir, v[\"imId\"])\n",
        "        print(filename)\n",
        "        # Get the height and width out using opencv\n",
        "        # height, width = cv2.imread(filename).shape[:2]\n",
        "\n",
        "        break\n",
        "    \n",
        "\n",
        "# json_file = os.path.join(img_dir, \"data.json\")\n",
        "# Open the file, referring it as f\n",
        "with open(\"data.json\") as f:\n",
        "  # Get the image annotations out using json to read the file containin the JSON object\n",
        "  imgs_anns = json.load(f)\n",
        "\n",
        "# for idx, v in enumerate(imgs_anns.values()):\n",
        "for idx, v in enumerate(imgs_anns):\n",
        "  # print(1)\n",
        "  print(\"imId: \", v[\"imId\"])\n",
        "  print(\"id: \", v[\"id\"])\n",
        "  print(\"side: \", v[\"side\"])\n",
        "  print(\"box_ymin_xmin_ymax_xmax: \", v[\"box_ymin_xmin_ymax_xmax\"])\n",
        "  break\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imId:  e26acf54-7e00-402a-9b81-8d68309069e8\n",
            "id:  R-1036\n",
            "side:  left\n",
            "box_ymin_xmin_ymax_xmax:  [40, 34, 266, 336]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJeuNo2T62h3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import json\n",
        "# from detectron2.structures import BoxMode\n",
        "\n",
        "# # This function will return the items in our dataset\n",
        "# def get_shark_dicts(img_dir):\n",
        "#     # Find the json file in our file structure\n",
        "#     json_file = os.path.join(img_dir, \"data.json\")\n",
        "#     # Open the file, referring it as f\n",
        "#     with open(json_file) as f:\n",
        "#         # Get the image annotations out using json to read the file containin the JSON object\n",
        "#         imgs_anns = json.load(f)\n",
        "\n",
        "#     # List of dictionaries\n",
        "#     dataset_dicts = []\n",
        "#     # Loop over the image annotation values, using idx as the indexer and v to be the value\n",
        "#     for idx, v in enumerate(imgs_anns.values()):\n",
        "#         # Create a dictionary for the current iteration\n",
        "#         record = {}\n",
        "        \n",
        "#         # Get the filename out of the file - \"filename\" is a key in the json file\n",
        "#         filename = os.path.join(img_dir, v[\"imId\"])\n",
        "#         # Get the height and width out using opencv\n",
        "#         height, width = cv2.imread(filename).shape[:2]\n",
        "        \n",
        "#         # The full path to the image file\n",
        "#         record[\"file_name\"] = filename\n",
        "#         # A unique id that identifies this image\n",
        "#         record[\"image_id\"] = idx\n",
        "#         # Shape of the image\n",
        "#         record[\"height\"] = height\n",
        "#         record[\"width\"] = width\n",
        "      \n",
        "#         # get all annotations, using the regions key - \"regions\" is a key in the json file\n",
        "#         annos = v[\"regions\"]\n",
        "#         # List of objects\n",
        "#         objs = []\n",
        "#         # For each annotation in the list of annotations\n",
        "#         for _, anno in annos.items():\n",
        "#             # assert throws an AssertionError if untrue\n",
        "#             # I think this is just to make sure region attributes is empty\n",
        "#             assert not anno[\"region_attributes\"]\n",
        "            \n",
        "#             # Turn the annotation into the shape attributes object in the file\n",
        "#             anno = anno[\"shape_attributes\"]\n",
        "#             # Get all x and y points\n",
        "#             px = anno[\"all_points_x\"]\n",
        "#             py = anno[\"all_points_y\"]\n",
        "#             # form a list of polygons, some mad functional stuff here\n",
        "#             poly = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
        "#             poly = [p for x in poly for p in x]\n",
        "\n",
        "#             # Form the object that will form our annotations\n",
        "#             obj = {\n",
        "#                 # list of 4 numbers representing the bounding box\n",
        "#                 \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "#                 # format of the bbox (must be a member of structures.BoxMode)\n",
        "#                 \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "#                 # list of list of floats, where a list of floats is a polygon\n",
        "#                 # so this is a list of polygons for segmentation\n",
        "#                 \"segmentation\": [poly],\n",
        "#                 # the category label, integer from 0 to numCategories - see Categorical Data\n",
        "#                 \"category_id\": 0,\n",
        "#                 # 0 or 1, whether this instance is labeled as COCO's crowd regions - don't include this if you don't know what this means\n",
        "#                 \"iscrowd\": 0\n",
        "#             }\n",
        "#             objs.append(obj)\n",
        "        \n",
        "#         # The per-instance annotation of every instance in this image\n",
        "#         record[\"annotations\"] = objs\n",
        "\n",
        "#         # Append this record\n",
        "#         dataset_dicts.append(record)\n",
        "        \n",
        "#         ### Loop end ###\n",
        "    \n",
        "#     # return the list of dictionaries\n",
        "#     return dataset_dicts\n",
        "\n",
        "# # We tell detectron2 about our newly created function\n",
        "# from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "# for d in [\"train\", \"val\"]:\n",
        "#     # Register this dataset in the catalog of datasets\n",
        "#     DatasetCatalog.register(\"balloon_\" + d, lambda d=d: get_balloon_dicts(\"balloon/\" + d))\n",
        "#     # Get the metadata catalog and add the corresponding metadata\n",
        "#     ## Metadata is a key-value mapping that contains primitive information that helps interpret what's in the dataset (eg names of classes)\n",
        "#     ## Useful for augmentation, evaluation, visualisation, logging, etc.\n",
        "#     MetadataCatalog.get(\"balloon_\" + d).set(thing_classes=[\"balloon\"])\n",
        "# balloon_metadata = MetadataCatalog.get(\"balloon_train\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}